{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e5a7b",
   "metadata": {},
   "source": [
    "# Project, exploring the Hubble \"Tension\"\n",
    "\n",
    "Recall that in weeks 1 and 2 of this course we explored some measurements of the Hubble constant and used them to study some simple statistics, and to uise inverse variance weighting to make a weighted average of measurements that took into account the fact that the some of the measurements had smaller uncertainties than others.\n",
    "\n",
    "It turns out that the consistency (or potential inconsistency) is the measurements of the Hubble constant is actually one of the biggest open questions in cosmology.  Roughly speaking, measurements of the Hubble constant can be divided into two types. \n",
    "\n",
    "1. \"Early time\" measurements that use our knowledge of cosmology, and look at structures in the very early universe, e.g., using the primoridal background of light left over from the Big Bang that is now visible to us as a bath of faint microwave radiation, to determine the Hubble parameter.  These measurements are more sensitive to our understanding of cosmology.\n",
    "\n",
    "2. \"Late time\" measurements that use supernovae and build on the so-called distance ladder to estimate the distance to the supernovae, and then compare that to the redshift of their spectral lines (i.e., the sort of measurement we did in week 6 looking at the spectrum of a Galaxy using SDSS data).  These measurements are more sensitive to our ability to build up a distance ladder out to billions of light years away.\n",
    "\n",
    "We've provided you with a new data file, which is a sub-set of the more recent Hubble data measurements, including an extra column telling you if a particular measurement is type 1 or type 2.\n",
    "\n",
    "Here are some things that you might try and do:\n",
    "\n",
    "1. Make a nice plot that summarize the difference between \"Early Time\" results and \"Late Time\" results\n",
    "\n",
    "2. Come up with some way to estimate how consistent the data within each subset (\"Early Time\" and \"Late Time\") are with themselves.\n",
    "\n",
    "3. Come up with some way to estimate how consistent the two different subsets (\"Early Time\" and \"Late Time\") are with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"../data/Hubble_Extra.txt\", 'rb'), usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we pull out the data from columns in the array.\n",
    "H0_measured = data[:,0]\n",
    "H0_errorLow = data[:,1]\n",
    "H0_errorHigh = data[:,2]\n",
    "H0_type = data[:,3]\n",
    "N_measurements = H0_measured.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b8bf1",
   "metadata": {},
   "source": [
    "# Here a couple of useful functions.\n",
    "\n",
    "The first one pulls out some useful statistical quantities, given arrays of values and associated error estimates\n",
    "\n",
    "The second one takes a set of Hubble parameter measurements, and the associated error bars (both low and high side) and prints out the statistical quantities and also make a plot of the measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(values, errors):\n",
    "    nvals = np.size(values)\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    err = std / np.sqrt(nvals)\n",
    "    wts = 1/(errors*errors)\n",
    "    wmean = np.sum(values*wts)/np.sum(wts)\n",
    "    werr = np.sqrt(1/np.sum(wts))\n",
    "    return (nvals, mean, std, err, wmean, werr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsAndPlotValues(values, errs_lo, errs_hi):\n",
    "    errs = 0.5*(errs_lo + errs_hi)\n",
    "    stats = getStats(values, errs)\n",
    "    print(\"Statistics for these data ----\")\n",
    "    print(\"N                      : %i\" % stats[0])\n",
    "    print(\"Mean                   : %0.2f\" % stats[1])\n",
    "    print(\"Standard Deviation     : %0.2f\" % stats[2])\n",
    "    print(\"Standard Error         : %0.2f\" % stats[3])\n",
    "    print(\"Weighted Mean          : %0.2f\" % stats[4])\n",
    "    print(\"Error on Weighted Mean : %0.2f\" % stats[5])\n",
    "    _ = plt.errorbar(values, np.arange(stats[0]), xerr=(errs_lo, errs_hi), fmt=\".\", color='k')\n",
    "    _ = plt.xlabel(\"Hubble Constant [km/s/Mpc]\")\n",
    "    _ = plt.ylabel(\"Experiment number\")\n",
    "    _ = plt.errorbar(stats[1], stats[0]/2., xerr=stats[3], yerr=stats[0]/2, fmt='o', color='b', label=\"Mean\")\n",
    "    _ = plt.errorbar(stats[4], stats[0]/2., xerr=stats[5], yerr=stats[0]/2, fmt='o', color=\"r\", label=\"Weighted Mean\")\n",
    "    _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getStatsAndPlotValues(H0_measured, H0_errorLow, H0_errorHigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf86ed",
   "metadata": {},
   "source": [
    "# Masking data by measurement type\n",
    "\n",
    "This next cell shows how to select measurements of either type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_1_mask = H0_type == 1\n",
    "type_2_mask = H0_type == 2\n",
    "print(\"Early time measurements\", H0_measured[type_1_mask])\n",
    "print(\"Late time measurements\", H0_measured[type_2_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc2c23",
   "metadata": {},
   "source": [
    "# Going from significance in sigma to p-value and vice versa\n",
    "\n",
    "These functions might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_value = 3\n",
    "p_value = sps.norm().sf(sigma_value)\n",
    "sigma_check = sps.norm().isf(p_value)\n",
    "print(\"Original sigma : %.2f\" % sigma_value)\n",
    "print(\"P-value        : %.2e\" % p_value)\n",
    "print(\"Back to sigma  : %.2f\" % sigma_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a5a11",
   "metadata": {},
   "source": [
    "# Going from a chi-squared for n degrees for freedom to a p-value\n",
    "\n",
    "This function tells you the p-value to observe total chi squared value given df = n-1 measurements.\n",
    "\n",
    "Where df is the \"degrees of freedom\", in our case, we might have, say, 11 measuements, but then we are picking one value of the Hubble constant to try and match all the data, so that leaves us with 10 \"degrees of freedom\".\n",
    "\n",
    "I.e., if we had a 11 measurements, and the total chi squared summed up to 11.5, then the p-value would be about 0.36/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The p-value for chi squared = 11.5 with 10 degrees of freedom is %0.2f\" % sps.chi2(df=10).sf(11.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd90b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4e497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
